#!/bin/bash

# List of experiments to run with non-downsampled data (i.e. 160 slices)
#
# @usage (from terminal/command line):
# ./non-downsampled-exps GPU_ID(s)
# eg: "./non-downsampled-exps 0", "./non-downsampled-exps 0,1"
#
# @initialization protocol:
#   1. run "chmod +x non-downsampled-exps" from the command line
#
# @author: Arjun Desai, Stanford University
#          (c) Stanford University, 2019

TOTAL_EXPS=(1)

if [ $# -lt 1 ]; then
	echo "Please provide gpus to run inference on in format `0` for single gpu or `0,1,2` for multiple gpus"
	exit 125
fi

# Navigate to project directory
cd ../..

ARGS='--use_step_decay --initial_learning_rate 0.02 --experiment non-downsampled -g '$GPU
NEW_PATHS_ARGS='--train_path /bmrNAS/people/akshay/dl/oai_data/oai_3d/train --valid_path /bmrNAS/people/akshay/dl/oai_data/oai_3d/valid --test_path /bmrNAS/people/akshay/dl/oai_data/oai_3d/test'
ARGS=$ARGS' '$NEW_PATHS_ARGS

# Experiment 1: 2d unet train
python -m oai_train unet_2d $ARGS

# Experiment 2: 3D unet (4 slices)
python -m oai_train unet_3d -g $GPU --img_size '(288,288,4,1)' --train_batch_size 1 $ARGS

# Experiment 3: 3D unet (8 slices)
python -m oai_train unet_3d -g $GPU --img_size '(288,288,8,1)' --train_batch_size 1 $ARGS

# Experiment 4: 3D unet (16 slices)
python -m oai_train unet_3d -g $GPU --img_size '(288,288,16,1)' --train_batch_size 1 $ARGS

# Experiment 5: 3D unet (32 slices)
python -m oai_train unet_3d -g $GPU --img_size '(288,288,32,1)' --train_batch_size 1 $ARGS
